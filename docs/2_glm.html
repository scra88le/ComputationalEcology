<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Generalised Linear Models (GLMs)</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computational Ecology</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="1_data_analysis.html">Data Analysis</a>
    </li>
    <li>
      <a href="2_glm.html">Generalised Linear Models</a>
    </li>
    <li>
      <a href="3_gam.html">Generalised Additive Models</a>
    </li>
    <li>
      <a href="4_sdm.html">Distribution Modelling</a>
    </li>
    <li>
      <a href="5_eDNA.html">Environmental DNA</a>
    </li>
    <li>
      <a href="6_sam_naboisho.html">Geostatistics</a>
    </li>
    <li>
      <a href="7_movement_BA055.html">Movement Modelling</a>
    </li>
    <li>
      <a href="8_distance_sampling.html">Distance Sampling</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Generalised Linear Models (GLMs)</h1>

</div>


<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>In classical linear regression model we make predictions of the <em>expected value</em> of a response variable as a function of the linear sum of covariates (also known as independent, explanatory or predictor variables). Generalised Linear Modelling (GLM) relaxes the constraintthat ordinary linear regression has, in that the response variable does not have to be normally distributed.</p>
<p>Why is the GLM useful for ecology problems? Often in ecology the response variable is in the form of a count of species presence or absence, and in general the response variable exhibits a mean-variance relationship that is not normally distributed.</p>
<div id="three-key-properties-of-the-glm" class="section level2">
<h2><span class="header-section-number">1.1</span> Three key properties of the GLM</h2>
<ol style="list-style-type: decimal">
<li>In a GLM it is assumed that the response variable (and residual errors) is from a distribution in the exponential family. The distributions from the exponential family and their relevance comprise:</li>
</ol>
<ul>
<li><em>Negative binomial</em> regression - non-negative count data, but variance can vary independently of the mean in order to handle <em>overdispersion</em></li>
<li><em>Poisson</em> regression - non-negative count data. Here the mean equals the variance. A sub-class of the negative binomial</li>
<li><em>Gamma</em> regression - can be used with positive continuous data</li>
<li><em>Binomial</em> (or logistic) regression - typically used with binary or proportional data.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>The response variable is a linear sum of the predictor variables</p></li>
<li><p>There is a linear relationship between a function g (the <em>link function</em> ) of the mean of the response variable, and the predictor variables. This function is used to transform the non-linear relationship to a linear one. There are a number of different link functions for each response variable distribution.</p></li>
</ol>
<p>More detail on the mathematical basis for the GLM, and associated link functions, can be found here<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p>
<p>Let’s start by loading the relevant libraries and some data.</p>
</div>
<div id="the-doubs-dataset" class="section level2">
<h2><span class="header-section-number">1.2</span> The Doubs dataset</h2>
<p>As in the Data Analysis vignette we will be using the doubs<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> dataset inorder to create a GLM. Here the response is count data (species abundance) for river fish species across 30 sites. From our brief discussion above this means the data are likely to be drawn from a <code>Poisson</code> distribution. The covariates are a number of environment measurements of water chemistry and physical characteristics, at each of the 30 sites.</p>
<pre class="r"><code>#Let&#39;s load the data
data(doubs)

# Set-up species data
species &lt;- doubs$fish

# Set-up environmental data
environ &lt;- doubs$env</code></pre>
<p>We can get a quick overview of the response data (species counts at each of the 30 sites) set using the <code>skimr</code> package:</p>
<pre class="r"><code># Look at the data - drop the site column
skim(species)</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">species</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">30</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">27</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">27</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Cogo</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.50</td>
<td align="right">0.94</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">0.75</td>
<td align="right">3</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Satr</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.90</td>
<td align="right">2.04</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">3.75</td>
<td align="right">5</td>
<td align="left">▇▁▂▁▃</td>
</tr>
<tr class="odd">
<td align="left">Phph</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.27</td>
<td align="right">1.98</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3.0</td>
<td align="right">4.00</td>
<td align="right">5</td>
<td align="left">▇▁▂▅▂</td>
</tr>
<tr class="even">
<td align="left">Neba</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.43</td>
<td align="right">1.92</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.0</td>
<td align="right">4.00</td>
<td align="right">5</td>
<td align="left">▇▂▂▂▅</td>
</tr>
<tr class="odd">
<td align="left">Thth</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.50</td>
<td align="right">1.01</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">0.75</td>
<td align="right">4</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Teso</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.63</td>
<td align="right">1.30</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">0.75</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Chna</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.60</td>
<td align="right">0.86</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.00</td>
<td align="right">3</td>
<td align="left">▇▃▁▂▁</td>
</tr>
<tr class="even">
<td align="left">Chto</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.87</td>
<td align="right">1.31</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">2.00</td>
<td align="right">4</td>
<td align="left">▇▁▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">Lele</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.43</td>
<td align="right">1.50</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">2.00</td>
<td align="right">5</td>
<td align="left">▇▃▂▁▁</td>
</tr>
<tr class="even">
<td align="left">Lece</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.87</td>
<td align="right">1.36</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.0</td>
<td align="right">3.00</td>
<td align="right">5</td>
<td align="left">▇▅▃▂▁</td>
</tr>
<tr class="odd">
<td align="left">Baba</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.43</td>
<td align="right">1.76</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">3.00</td>
<td align="right">5</td>
<td align="left">▇▂▂▂▁</td>
</tr>
<tr class="even">
<td align="left">Spbi</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.90</td>
<td align="right">1.40</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Gogo</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.83</td>
<td align="right">1.84</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">3.75</td>
<td align="right">5</td>
<td align="left">▇▂▁▂▂</td>
</tr>
<tr class="even">
<td align="left">Eslu</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.33</td>
<td align="right">1.52</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">2.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Pefl</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.20</td>
<td align="right">1.54</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.5</td>
<td align="right">2.00</td>
<td align="right">5</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Rham</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.10</td>
<td align="right">1.65</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">2.00</td>
<td align="right">5</td>
<td align="left">▇▁▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">Legi</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.97</td>
<td align="right">1.40</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.75</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Scer</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.70</td>
<td align="right">1.15</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.00</td>
<td align="right">5</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Cyca</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.83</td>
<td align="right">1.34</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Titi</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.50</td>
<td align="right">1.74</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">3.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▂▁</td>
</tr>
<tr class="odd">
<td align="left">Abbr</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.87</td>
<td align="right">1.53</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Icme</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.60</td>
<td align="right">1.30</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Acce</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.27</td>
<td align="right">1.89</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">2.00</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▂</td>
</tr>
<tr class="even">
<td align="left">Ruru</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.10</td>
<td align="right">2.20</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">5.00</td>
<td align="right">5</td>
<td align="left">▇▂▁▁▅</td>
</tr>
<tr class="odd">
<td align="left">Blbj</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.03</td>
<td align="right">1.71</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.75</td>
<td align="right">5</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Alal</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.90</td>
<td align="right">2.25</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">5.00</td>
<td align="right">5</td>
<td align="left">▇▂▁▁▅</td>
</tr>
<tr class="odd">
<td align="left">Anan</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.90</td>
<td align="right">1.45</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">1.75</td>
<td align="right">5</td>
<td align="left">▇▂▁▁▁</td>
</tr>
</tbody>
</table>
<p>We can see that there are 27 species, with no missing data. Some are more numerous than others, but it doesn’t seem like the data are overdisperesed. It’s clear from the simplified histrogram column that species counts are not nomrally distributed, and that a <em>Poisson</em> distribution is probably a good fit for response variable data.</p>
<p>Similarly for the covariate dataset:</p>
<pre class="r"><code># Look at the data - drop the site column
skim(environ)</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">environ</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">30</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">11</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">dfs</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1879.03</td>
<td align="right">1396.51</td>
<td align="right">3.0</td>
<td align="right">544.50</td>
<td align="right">1752.00</td>
<td align="right">3017.25</td>
<td align="right">4530.00</td>
<td align="left">▇▅▅▅▃</td>
</tr>
<tr class="even">
<td align="left">alt</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">481.50</td>
<td align="right">271.39</td>
<td align="right">172.0</td>
<td align="right">248.00</td>
<td align="right">395.00</td>
<td align="right">782.00</td>
<td align="right">934.00</td>
<td align="left">▇▃▂▁▅</td>
</tr>
<tr class="odd">
<td align="left">slo</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.76</td>
<td align="right">1.08</td>
<td align="right">1.1</td>
<td align="right">1.83</td>
<td align="right">2.56</td>
<td align="right">3.39</td>
<td align="right">6.18</td>
<td align="left">▆▇▅▂▁</td>
</tr>
<tr class="even">
<td align="left">flo</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2220.10</td>
<td align="right">1810.19</td>
<td align="right">84.0</td>
<td align="right">420.00</td>
<td align="right">2210.00</td>
<td align="right">2857.50</td>
<td align="right">6900.00</td>
<td align="left">▇▇▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">pH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">80.50</td>
<td align="right">1.74</td>
<td align="right">77.0</td>
<td align="right">79.25</td>
<td align="right">80.00</td>
<td align="right">81.00</td>
<td align="right">86.00</td>
<td align="left">▁▇▆▂▁</td>
</tr>
<tr class="even">
<td align="left">har</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">86.10</td>
<td align="right">16.87</td>
<td align="right">40.0</td>
<td align="right">84.25</td>
<td align="right">89.00</td>
<td align="right">96.75</td>
<td align="right">110.00</td>
<td align="left">▂▁▁▇▃</td>
</tr>
<tr class="odd">
<td align="left">pho</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">55.77</td>
<td align="right">87.64</td>
<td align="right">1.0</td>
<td align="right">12.50</td>
<td align="right">28.50</td>
<td align="right">56.00</td>
<td align="right">422.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">nit</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">165.40</td>
<td align="right">141.34</td>
<td align="right">15.0</td>
<td align="right">50.50</td>
<td align="right">160.00</td>
<td align="right">242.50</td>
<td align="right">620.00</td>
<td align="left">▇▆▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">amm</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">20.93</td>
<td align="right">37.91</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">10.00</td>
<td align="right">20.00</td>
<td align="right">180.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">oxy</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">93.90</td>
<td align="right">22.15</td>
<td align="right">41.0</td>
<td align="right">80.25</td>
<td align="right">102.00</td>
<td align="right">109.00</td>
<td align="right">124.00</td>
<td align="left">▂▃▃▇▆</td>
</tr>
<tr class="odd">
<td align="left">bdo</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">51.17</td>
<td align="right">38.64</td>
<td align="right">13.0</td>
<td align="right">27.25</td>
<td align="right">41.50</td>
<td align="right">52.75</td>
<td align="right">167.00</td>
<td align="left">▇▃▁▁▁</td>
</tr>
</tbody>
</table>
<p>We can see that there are no missing data. We can visualise the response data against the covariates using the <code>featurePlot</code> function from the <code>caret</code> library.</p>
<pre class="r"><code>featurePlot(x=environ, y= species$Ruru)</code></pre>
<p><img src="2_glm_files/figure-html/feature_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>With this simple chart we see how the count for <em>Ruru</em> species is at a maximum for relatively low concentrations for ammonium and phosphate (<code>amm</code> and <code>pho</code>) and high values for chalkiness (<code>har</code>) of the river water.</p>
<p>Given the response and covariate datasets we can fit a GLM with the doubs data. We fit the count data for the species <em>Ruru</em> against all environmental covariates, usung a Poisson distribution. A response variable that is Poisson distributed usually has a log link function. Note, we know from the Data Analysis vignette that some covariates within the <code>environ</code> dataset have significant collinearity, so the model results may not be ideal.</p>
<pre class="r"><code># Fit GLM to species Ruru - use all environmental covariates to fit the model
ruru_model &lt;- glm(formula = species$Ruru ~ . ,  
                     # Use a Poisson distribution for the response variable
                     family= poisson(link = &quot;log&quot;), 
                     data = environ)

# Summarise the model fit
summary(ruru_model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = species$Ruru ~ ., family = poisson(link = &quot;log&quot;), 
##     data = environ)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.57253  -0.88709  -0.34156   0.08549   2.79357  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  2.119e+01  8.809e+00   2.405   0.0162 *
## dfs         -4.277e-04  1.537e-03  -0.278   0.7809  
## alt         -3.473e-03  4.513e-03  -0.770   0.4415  
## slo         -4.544e-01  3.546e-01  -1.281   0.2000  
## flo          7.666e-05  6.587e-04   0.116   0.9074  
## pH          -1.001e-01  1.297e-01  -0.772   0.4400  
## har         -9.824e-03  2.253e-02  -0.436   0.6627  
## pho         -8.443e-03  7.057e-03  -1.196   0.2316  
## nit         -3.028e-04  4.054e-03  -0.075   0.9405  
## amm          1.575e-02  1.903e-02   0.828   0.4079  
## oxy         -7.058e-02  3.580e-02  -1.971   0.0487 *
## bdo         -3.361e-02  1.867e-02  -1.800   0.0718 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 81.864  on 29  degrees of freedom
## Residual deviance: 31.361  on 18  degrees of freedom
## AIC: 109.06
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>To understand which covariates are significant in the GLM, we can look at the p values associated with each covariate in the table above. We can see that the <code>oxy</code> covariate is significant as a predictor for Ruru abundance, when all covariates are used to fit a model.</p>
<p>We can also check to see if the model fit is over or under-dispersed by looking at the <em>residual deviance</em>. If the residual deviance is substantially greater than the degrees of freedom, then the model is over-dispersed; the predicted values are correct but the standard deviation are not accounted for by the model. In the model fit above the residual deviance is fairly close to the degrees of freedom, and the dispersion parameter is 31.361/18 = 1.74 (which is small), so the model is a good fit.</p>
<p>The <em>null deviance</em> shows the predicted response when only the intercept (the overall mean) is included in the data. We can see that adding the covariates into the model reduces the null-deviance by around 50. Again, a good sign in terms of the model’s overall suitability.</p>
<p>We can use an ANOVA test to check if treatments have an effect. For GLMs this is often called an <em>analysis of deviance</em> table.</p>
<pre class="r"><code># Genrate analysis of deviance
anova(ruru_model, test=&quot;LRT&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model: poisson, link: log
## 
## Response: species$Ruru
## 
## Terms added sequentially (first to last)
## 
## 
##      Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
## NULL                    29     81.864              
## dfs   1  27.4477        28     54.416 1.614e-07 ***
## alt   1   0.0153        27     54.401  0.901578    
## slo   1   2.5813        26     51.819  0.108131    
## flo   1   2.7178        25     49.102  0.099235 .  
## pH    1   1.8157        24     47.286  0.177830    
## har   1   0.3063        23     46.980  0.579979    
## pho   1   9.5635        22     37.416  0.001985 ** 
## nit   1   0.7029        21     36.713  0.401809    
## amm   1   0.1921        20     36.521  0.661175    
## oxy   1   1.7001        19     34.821  0.192279    
## bdo   1   3.4598        18     31.361  0.062878 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We can see that the <code>dfs</code> and <code>pho</code> treatments seem to have a significant effect on the abundance of Ruru. From eyeballing the feature plot above we can see that there is a linear relationship between Ruru abundance and the distance from the source, and an inverse linear relationship between phosphorus concentration and Ruru abundnace. So the analysis of deviance results appear to make sense.</p>
</div>
<div id="stepwise-regression-and-aic" class="section level2">
<h2><span class="header-section-number">1.3</span> Stepwise regression and AIC</h2>
<p>We can perform a stepwise regression whereby we fit a model with increasingly smaller subsets of covariates for the given response variable, and select the best model-fit according to the AIC results of the model. The basic idea of Akaike’s Information Criteria (AIC) is to penalize the inclusion of additional variables to a model. In general, the lower the AIC, the better the model. Our initial model fit gave an AIC of 109.</p>
<pre class="r"><code># Step through combinations
step_ruru &lt;- step(glm(species$Ruru~., data=environ, family=poisson))</code></pre>
<pre><code>## Start:  AIC=109.06
## species$Ruru ~ dfs + alt + slo + flo + pH + har + pho + nit + 
##     amm + oxy + bdo
## 
##        Df Deviance    AIC
## - nit   1   31.367 107.06
## - flo   1   31.375 107.07
## - dfs   1   31.439 107.14
## - har   1   31.549 107.25
## - alt   1   31.967 107.67
## - pH    1   31.982 107.68
## - amm   1   32.078 107.78
## - pho   1   32.790 108.49
## - slo   1   33.104 108.80
## &lt;none&gt;      31.361 109.06
## - bdo   1   34.821 110.52
## - oxy   1   35.640 111.34
## 
## Step:  AIC=107.06
## species$Ruru ~ dfs + alt + slo + flo + pH + har + pho + amm + 
##     oxy + bdo
## 
##        Df Deviance    AIC
## - flo   1   31.410 105.11
## - dfs   1   31.503 105.20
## - har   1   31.594 105.29
## - pH    1   31.985 105.68
## - alt   1   31.999 105.70
## - amm   1   32.537 106.23
## - pho   1   33.089 106.79
## - slo   1   33.106 106.80
## &lt;none&gt;      31.367 107.06
## - oxy   1   35.755 109.45
## - bdo   1   36.295 109.99
## 
## Step:  AIC=105.11
## species$Ruru ~ dfs + alt + slo + pH + har + pho + amm + oxy + 
##     bdo
## 
##        Df Deviance    AIC
## - har   1   31.607 103.31
## - dfs   1   31.736 103.44
## - amm   1   32.540 104.24
## - pH    1   32.894 104.59
## - alt   1   33.101 104.80
## - pho   1   33.114 104.81
## &lt;none&gt;      31.410 105.11
## - slo   1   33.985 105.68
## - bdo   1   36.574 108.27
## - oxy   1   42.050 113.75
## 
## Step:  AIC=103.31
## species$Ruru ~ dfs + alt + slo + pH + pho + amm + oxy + bdo
## 
##        Df Deviance    AIC
## - dfs   1   32.150 101.85
## - amm   1   32.863 102.56
## - pH    1   33.013 102.71
## - pho   1   33.310 103.01
## - alt   1   33.440 103.14
## &lt;none&gt;      31.607 103.31
## - slo   1   34.004 103.70
## - bdo   1   37.524 107.22
## - oxy   1   43.062 112.76
## 
## Step:  AIC=101.85
## species$Ruru ~ alt + slo + pH + pho + amm + oxy + bdo
## 
##        Df Deviance    AIC
## - pH    1   33.795 101.49
## &lt;none&gt;      32.150 101.85
## - amm   1   34.255 101.95
## - slo   1   34.430 102.13
## - alt   1   34.853 102.55
## - pho   1   34.932 102.63
## - bdo   1   37.748 105.45
## - oxy   1   46.584 114.28
## 
## Step:  AIC=101.49
## species$Ruru ~ alt + slo + pho + amm + oxy + bdo
## 
##        Df Deviance    AIC
## - slo   1   35.054 100.75
## - amm   1   35.606 101.30
## &lt;none&gt;      33.795 101.49
## - pho   1   36.428 102.13
## - alt   1   37.834 103.53
## - bdo   1   38.600 104.30
## - oxy   1   48.861 114.56
## 
## Step:  AIC=100.75
## species$Ruru ~ alt + pho + amm + oxy + bdo
## 
##        Df Deviance    AIC
## - amm   1   36.579 100.28
## - pho   1   36.901 100.60
## &lt;none&gt;      35.054 100.75
## - bdo   1   41.831 105.53
## - alt   1   48.873 112.57
## - oxy   1   55.110 118.81
## 
## Step:  AIC=100.28
## species$Ruru ~ alt + pho + oxy + bdo
## 
##        Df Deviance     AIC
## - pho   1   36.994  98.692
## &lt;none&gt;      36.579 100.277
## - bdo   1   42.069 103.767
## - alt   1   49.195 110.893
## - oxy   1   55.310 117.009
## 
## Step:  AIC=98.69
## species$Ruru ~ alt + oxy + bdo
## 
##        Df Deviance     AIC
## &lt;none&gt;      36.994  98.692
## - alt   1   50.090 109.788
## - bdo   1   56.975 116.673
## - oxy   1   57.480 117.178</code></pre>
<pre class="r"><code># Summarise best model by AIC
summary(step_ruru)</code></pre>
<pre><code>## 
## Call:
## glm(formula = species$Ruru ~ alt + oxy + bdo, family = poisson, 
##     data = environ)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5738  -1.0623  -0.5900   0.5709   2.7048  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  8.4958149  1.5616062   5.440 5.32e-08 ***
## alt         -0.0019890  0.0006159  -3.230 0.001240 ** 
## oxy         -0.0596173  0.0141202  -4.222 2.42e-05 ***
## bdo         -0.0312781  0.0081093  -3.857 0.000115 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 81.864  on 29  degrees of freedom
## Residual deviance: 36.994  on 26  degrees of freedom
## AIC: 98.692
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>The best model has resulted in an AIC of 99; about a 10% improvement of our initial model. This is because we only need three covariates, <code>alt</code>, <code>oxy</code> and <code>bdo</code>, to give a similar result as our first model that had all 11 covariates</p>
</div>
</div>
<div id="a-general-modelling-protocol" class="section level1">
<h1><span class="header-section-number">2</span> A general modelling protocol</h1>
<p>A general protcol for how to proceed with predictive modelling, for both statistical regression and machine learning techinuqes, is presented below. When using a technique to fit covariates to response data, there are four key steps. In this vignette we will focus on the GLM, but the approach is equally valid for other modelling methods too. The four steps are:</p>
<ol style="list-style-type: decimal">
<li>Split the available data into training and modelling data sets.</li>
<li>Choose a modelling method and fit the model</li>
<li>Use the model fit to make predictions</li>
<li>Calculate the accuracy of the model predictions using relevant metrics.</li>
</ol>
</div>
<div id="caret" class="section level1">
<h1><span class="header-section-number">3</span> Caret</h1>
<p>We are going to use the r package <code>caret</code> to fit a model. The package is highly flexible and can be used to fit many different types of regression and machine learning models. We start by looking at the relationship between each predictor variable and the response. First we split our data into train and test subsets. Each subset will be further split later on using a method known as k-fold cross validation. This involves splitting a dataset into k-subsets. Each subset is held out while the model is trained on all other subsets. This process is completed until accuracy is determined for each instance in the dataset, and an overall accuracy estimate is provided.</p>
<div id="covariate-selection" class="section level2">
<h2><span class="header-section-number">3.1</span> Covariate selection</h2>
<p>As we explored in the data analysis vignette, we should remove those covarits that have an absolute correlation of 80% or higher. We can establish this by calculating a correlation matrix and then selecting only those covariates with minimal collinearity, as follows:</p>
<pre class="r"><code># Generate covariate correlation matrix
cor_mat &lt;- cor(environ, method=&quot;spearman&quot;)
# Subset covariates that are highly correlated
highlyCorrelated &lt;- findCorrelation(cor_mat, cutoff=0.8)
# Generate column names to remove
cols_to_remove &lt;- names(environ[highlyCorrelated])
# Remove highly correlated variables from df
df_model &lt;- environ %&gt;% dplyr::select(-cols_to_remove)
# Create a dataframe of Ruru abundance and environmental covariates
df_model &lt;- cbind(abun = species$Ruru, df_model)
# Let&#39;s look at the results
head(df_model)</code></pre>
<pre><code>##   abun   slo pH har pho nit bdo
## 1    0 6.176 79  45   1  20  27
## 2    0 3.434 80  40   2  20  19
## 3    0 3.638 83  52   5  22  35
## 4    0 3.497 80  72  10  21  13
## 5    5 3.178 81  84  38  52  62
## 6    1 3.497 79  60  20  15  53</code></pre>
<p>So now we have six covariates (and we started with 11) that have minimal collinearity.</p>
</div>
<div id="splitting-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Splitting data</h2>
<p>We begin by splitting the data into train and testing sets. We give 60% of the data values over to training with the remainder used to test the model fit:</p>
<pre class="r"><code># Create index for splitting
inTrain  &lt;- createDataPartition(y = df_model$abun, p = 0.6, list = FALSE)
# Create training dataset
training &lt;- df_model[inTrain,]
# Create testing dataset
testing  &lt;- df_model[-inTrain,]</code></pre>
</div>
<div id="model-training" class="section level2">
<h2><span class="header-section-number">3.3</span> Model training</h2>
<p>Now we can proceed to fitting a GLM using the optimum features (covariates) that we have selected. We will use the <code>train</code> function within caret to do this as follows:</p>
<pre class="r"><code># For reproducibilty
set.seed(12345)

# Train the model
glm_fit &lt;- train(
  # Specify a formula for abundance as a function of selected covariates
  form = abun ~ . , 
  # Select data to train the model on
  data = training,
  # Select the glm method with the poisson distribution
  method = &quot;glm&quot;, family = &quot;poisson&quot;,
  # Normalise the covariate data
  preProcess = c(&quot;center&quot;, &quot;scale&quot;),
  # Tuning parameters
  trControl = trainControl(&quot;cv&quot;, 5, savePredictions = T))</code></pre>
<p>The <code>train</code> function can be tuned to implement <em>k-fold cross validation</em>. This involves splitting the dataset into k-subsets. Each subset is then <em>held out</em> while the model is trained on all other subsets. This process is repeated on all subsets and an overall accuracy estimate is provided. In the example above we implemented 5-fold cross validation.</p>
</div>
<div id="model-accuracy" class="section level2">
<h2><span class="header-section-number">3.4</span> Model accuracy</h2>
<p>Now we have successfully trained our GLM using caret, we can look at the model accuracy.</p>
<pre class="r"><code># How did the model perform
glm_fit</code></pre>
<pre><code>## Generalized Linear Model 
## 
## 19 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 15, 15, 15, 16, 15 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   3.681873  0.6456929  2.608131</code></pre>
<pre class="r"><code># Show model fit details and covariate significance
summary(glm_fit)</code></pre>
<pre><code>## 
## Call:
## NULL
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5904  -1.2316  -0.5274   0.3897   3.0385  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)   0.3383     0.2289   1.478  0.13941   
## slo          -0.8599     0.3021  -2.846  0.00443 **
## pH            0.1750     0.2365   0.740  0.45935   
## har          -0.1095     0.2765  -0.396  0.69219   
## pho          -1.0896     0.6063  -1.797  0.07229 . 
## nit           0.6144     0.2497   2.461  0.01387 * 
## bdo           0.5187     0.4356   1.191  0.23374   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 53.647  on 18  degrees of freedom
## Residual deviance: 26.972  on 12  degrees of freedom
## AIC: 74.349
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<pre class="r"><code># What are the important of the covariates in them model?
varImp(glm_fit) %&gt;% plot()</code></pre>
<p><img src="2_glm_files/figure-html/covar_fit-1.png" width="672" /></p>
<p>We can see that the model fit has the following accuracy metrics for the given training data:</p>
<ul>
<li>Root Mean Squared Error (RMSE) - this is the average error the model produces in predicting the output.</li>
<li>Rsquared (R2) - the proportion of variation in the outcome that is explained by the covariates within the model.</li>
<li>MAE - the average absolute difference between observed and predicted outcomes.</li>
</ul>
<p>The chart shows the relative importance of each covariate within the model. We can see that <code>pH</code> doesn’t seem to have an effect on the response variable in this model, with <code>pho</code> and <code>nit</code> having the most significant effect. This is also confirmed by looking at the model summary. The model summary also shows that our AIC has improved considerably too 76 and that the overdispersion of this model is significantly improved on the previous version.</p>
</div>
<div id="prediction-accuracy" class="section level2">
<h2><span class="header-section-number">3.5</span> Prediction accuracy</h2>
<p>In order to assess how well the model makes predictions, we can make a prediction using the test data and the model fit.</p>
<pre class="r"><code># how accurate was the trained model on the test data set?
# Make a prediction on the test data set
pred &lt;- predict(glm_fit, newdata = testing)

# Calculate prediction accuracy of model, given test data
data.frame(
  R2 = R2(pred, testing$abun),
  RMSE = RMSE(pred, testing$abun),
  MAE = MAE(pred, testing$abun)
)</code></pre>
<pre><code>##          R2     RMSE      MAE
## 1 0.1943634 4.597369 3.144024</code></pre>
</div>
</div>
<div id="discussion" class="section level1">
<h1><span class="header-section-number">4</span> Discussion</h1>
<p>GLMs are a relatively easy way of generating statistical predictions from species abundance data, given a set of associated covariates. Our final model for modelling Ruru abundance gave an improved residual deviance and AIC over the initial model, that contained all covariate data. As we will see in later vignettes, the <code>caret</code> package provides a generalised framework within which we can try many different modelling approaches in order to investigate ecological phenomena.</p>
</div>
<div id="references" class="section level1">
<h1><span class="header-section-number">5</span> References</h1>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Generalised Linear Modelling - <a href="https://en.wikipedia.org/wiki/Generalized_linear_model" class="uri">https://en.wikipedia.org/wiki/Generalized_linear_model</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Verneaux, J. (1973) Cours d’eau de Franche-Comté (Massif du Jura). Recherches écologiques sur le réseau hydrographique du Doubs. Essai de biotypologie. Thèse d’état, Besançon. 1–257. <em>Doubs river fish communities</em>. <a href="https://www.davidzeleny.net/anadat-r/doku.php/en:data:doubs" class="uri">https://www.davidzeleny.net/anadat-r/doku.php/en:data:doubs</a><a href="#fnref2">↩</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
