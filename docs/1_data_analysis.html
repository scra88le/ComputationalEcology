<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>A Protocol for Data Exploration</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computational Ecology</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="1_data_analysis.html">Data Analysis</a>
    </li>
    <li>
      <a href="2_glm.html">Generalised Linear Models</a>
    </li>
    <li>
      <a href="3_gam.html">Generalised Additive Models</a>
    </li>
    <li>
      <a href="4_sdm.html">Species Distribution Modelling</a>
    </li>
    <li>
      <a href="5_eDNA.html">Environmental DNA</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">A Protocol for Data Exploration</h1>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Undertaking a systematic data exploration prior to applying statistical analysis techniques to experimental data can help improve the statistical validity of results and associated conclusons. Key to this is a protocol for ensuring the scientist does not discover a false covariate effect (<em>type I error</em>) or wrongly dismiss a model was valid covariate (<em>type II error</em>).</p>
<p>The aim of this vignette is to provide a protocol for data exploration that identifies potential problems before any statistical analysis is undertaken. The approach outlined makes extensive use of the material discussed in <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Datasets are sourced from the Internet or academics at Oxford Brookes University.</p>
<p>The data exploration protocol outline is as follows:</p>
<ol style="list-style-type: decimal">
<li><strong>Outliers</strong> - observations that are relatively large or small when compared to the majority of observations, can significantly affect a statisical result.</li>
<li><strong>Homogeneity of variance</strong> - a number of statistical techniques assume homogeneity of variance of data. If this is violated the null hypothesis maybe falsely rejected or the power of the test maybe decrease.</li>
<li><strong>Normality</strong> - if data are not normally distributed, a number of statistical tests may not be valid, and alternative approaches will be required</li>
<li><strong>Zero-inflation</strong> - when modelling species counts, a large proportion of the data maybe zeros. In such cases alternative statistical models should be used to avoid biased estimates.</li>
<li><strong>Collinearity</strong> - avoiding correlation between covariates is important otherwise statistical outcomes may not be directly associated with specific covariates.</li>
<li><strong>Associations</strong> - in univariate analysis it is important to explore the indicative relationship between response variables and covariates.</li>
</ol>
</div>
<div id="are-there-outliers" class="section level1">
<h1>Are there outliers?</h1>
<p>In some statistical techniques the results are dominated by outliers; other techniques treat them like any other value. For example, outliers may cause overdispersion in a Poisson GLM. Outliers are defined as an observation that has a relatively large or small value compared to the majority of observations.</p>
<p>In order to demonstrate the data exploration step we will use data from species group sizes in the Naboisho Conservancy within Kenya. Here researchers recorded the size of species groups as they drove along a number of 2km transects.</p>
<div id="boxplots" class="section level2">
<h2>Boxplots</h2>
<p>The boxplot visualizes the median of the data and the spread of the data about it. In the chart below the:</p>
<ul>
<li>Median is presented as a vertical line within the white box</li>
<li>25% and 75% percentiles form a box around the median that contains half of the observations</li>
<li>Ends of the thin line either side of the white box are the upper and lower whiskers</li>
<li>Upper whisker covers values no larger (or smaller) than the inter-quartile range (the distance between the first and third quartiles)</li>
<li>Data beyond the whiskers are the outliers, and are shown as red dots.</li>
</ul>
<pre class="r"><code>naboisho %&gt;% 
  filter(species != &quot;None&quot;) %&gt;%
  ggplot(aes(x=species, y=log10(size))) +
  geom_boxplot(outlier.colour=&quot;red&quot;, 
               outlier.shape=16,
               outlier.size=0.75, 
               notch=F) +
  coord_flip() +
  ggtitle(&quot;Species group sizes in Naboisho Conservancy. 2016 to 2019&quot;) +
  xlab(&quot;Species&quot;) +
  ylab(&quot;Species group size - log10&quot;) +
  theme_bw()</code></pre>
<p><img src="1_data_analysis_files/figure-html/naboisho_box_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Note the x axis is scaled to log base 10, in order to compare species with small group sizes, such as Black Backed Jackal, against species with large group sizes such as Zebra or Wildebeest.</p>
</div>
<div id="cleveland-dot-plot" class="section level2">
<h2>Cleveland dot plot</h2>
<p><strong>Cleveland dotplot</strong> is a chart in which the row number of an observation is plotted vs. the observation value, thereby providing a more detailed view of individual observations than a boxplot allows. Points that stick out on the right-hand side, or on the left-hand side, are observed values that are considerable larger, or smaller, than the majority of the observations, and require further investigation.</p>
<p>The chart below shows a dot plot for each species within the Naboisho dataset from 2016 to 2019.</p>
<pre class="r"><code>naboisho %&gt;%
  filter(species != &quot;None&quot;) %&gt;% # Remove species with no name!
  ggplot(aes(x=size, y=seq(1, length(size)))) +
  geom_point(alpha=0.3) +
  ggtitle(&quot;Cleveland dot plot of Naboisho species 2016 to 2019&quot;) +
  labs(x = &quot;Observed group size of Species&quot;, 
       y = &quot;Order of data&quot;) +
  theme_bw() +
  facet_wrap(~species, ncol = 3, scales = &quot;free_x&quot;)</code></pre>
<p><img src="1_data_analysis_files/figure-html/cleveland_dot_all_species-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>For Giraffe we can see that there is a single outlier; a group size of 350 Giraffe. This is quite clearly a data entry error. If we remove this outlier and replot the dot plot, we see the following:</p>
<pre class="r"><code>naboisho %&gt;%
  filter(species == &quot;Giraffe&quot;) %&gt;%
  filter(size &lt;= 300) %&gt;%
  ggplot(aes(x=size, y=seq(1, length(size)))) +
  geom_point(alpha=0.3) +
  ggtitle(&quot;Cleveland dot plot of Giraffe Naboisho 2016 to 2019 - outliers removed&quot;) +
  labs(x = &quot;Observed group size of Giraffe&quot;, 
       y = &quot;Order of data&quot;) +
  theme_bw()</code></pre>
<p><img src="1_data_analysis_files/figure-html/cleveland_dot_giraffe_clean-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Note we also have a number of observations with group sizing of zero. This is clearly not possible and is probably due to a misunderstanding on behalf of the data recorder, and so we can correct this mistake accordingly:</p>
<pre class="r"><code>naboisho &lt;- naboisho %&gt;%
  mutate_all(funs(replace(., size == 0, 1)))</code></pre>
</div>
<div id="implications" class="section level2">
<h2>Implications</h2>
<p>Having determined that there are outliers in observations, we can take a number of steps to validate their inclusion or not:</p>
<ul>
<li>check the data to ensure that there has not been a data entry error</li>
<li>check the scientific literature to provide an expected value.</li>
<li>generate a number of observations randomly from an appropriate distribution, and determine how the proportion of extremem points compares to the field data</li>
</ul>
<p>If the outliers are deemed valid then it maybe necessary to only use statistical methods that can handle such <em>over-dispersed</em> data. For example, Poisson or negative-binomial distributions for count data.</p>
</div>
</div>
<div id="homogeneity-of-variance" class="section level1">
<h1>Homogeneity of variance</h1>
<p>Homogeneity of variance is an important assumption in analysis of variance (ANOVA). The plot below shows a boxplot for Wildebesst group size observations within the Naboisho dataset. In the plots below we have assumed that the long rains are from April to May, the short rains are in November and all other months are the dry season.</p>
<p>To apply ANOVA to these data to determine if mean Wildebeest group size varies by year, season or a combination of year and season, we must assume that variation:</p>
<ol style="list-style-type: decimal">
<li>In the years are similar</li>
<li>In observations for each season are similar</li>
<li>Between seasons within years are similar.</li>
</ol>
<pre class="r"><code># Add a column to the data set to determine month of year

naboisho &lt;- naboisho %&gt;% 
  mutate(Month = month(Date, label= T, abbr = T)) %&gt;%
  # Add a season column to data
  mutate(season = case_when(
    Month == &quot;Apr&quot; ~ &quot;long rains&quot;,           #long rains
    Month == &quot;May&quot; ~ &quot;long rains&quot;,           #long rains
    Month == &quot;Nov&quot; ~ &quot;short rains&quot;,           #short rains
    TRUE           ~ &quot;dry&quot;)) # Else it&#39;s the dry season
  
wildebeest_seasons &lt;- naboisho %&gt;%  
  # Take Widebeest only, and remove outliers for group size &gt; 500
  filter(species == &quot;Wildebeest&quot;, size &lt; 500) %&gt;%
  # Filter out 2016 as insufficient data to determine month
  filter(year != 2016)

wildebeest_seasons %&gt;%
  # Plot boxplots by season, don&#39;t display outliers
  ggplot(aes(x=season, y=size)) +
    geom_boxplot(outlier.shape=NA) +
    # Facet by year
    facet_wrap(. ~ year) +
    coord_cartesian(ylim=c(0, 90)) +
    theme_bw() +
    ggtitle(&quot;Boxplot of Wildebeest group size by season, across years (no outliers)&quot;) +
    labs(x = &quot;Season and year&quot;, 
         y = &quot;Observed group size of Wildebeest&quot;)</code></pre>
<p><img src="1_data_analysis_files/figure-html/widebeest_by_season-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We can see that the variance between seasons within a year is significantly different for 2017 and 2019. Therefore we should not undertake the classic ANOVA test if we want to analyse differences in group means within the years 2017 and 2019. Also we have more than two groups and because the size data are counts, we should not assume they are normally distributed.</p>
<div id="levennes-homogenrity-of-variance-test" class="section level2">
<h2>Levenne’s homogenrity of variance test</h2>
<p>We can directly test for homogeneity of variances by using <em>Levenne’s test</em>:</p>
<pre class="r"><code>library(car)

# Generate a two-way test to incorporate interaction between seasons and years
leveneTest(size ~ as.factor(season) * as.factor(year), data = wildebeest_seasons)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##         Df F value    Pr(&gt;F)    
## group    7  24.722 &lt; 2.2e-16 ***
##       9744                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>From the output above we can see that the p-value is much less than the significance level of 0.05. This means that we can not assume equal variances betweens years and seasons.</p>
<p>We therefore need to use a test that does not assume equal variance, can work for three different groups and is non-parametric. The <em>Kruskal-Wallis</em> test is a nonparametric (distribution free) test, and is used when the assumptions of one-way ANOVA are not met. The test can assess for significant differences on a continuous dependent variable (in our case, group size) by a two or more categorical independent variable groups (in our case the three different seasons). With this test we can ask the question if the mean group size between long rains, short rains and dry seasons is statistically different:</p>
<pre class="r"><code># Select 2017 wildebeest observations only
wildebeest_seasons %&gt;% filter(year == 2017) %&gt;% 
  kruskal.test(.$size, .$season, data = .)</code></pre>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  .$size and .$season
## Kruskal-Wallis chi-squared = 292.62, df = 2, p-value &lt; 2.2e-16</code></pre>
<p>As p &lt;&lt; 0.05, we can therefore reject the null hypothesis that the difference in means is zero. So the mean group size does vary by season in 2017. But between which groups is the differnce most significant? To answer this we need a post-hoc test, and for this we use a pairwise wilcox test:</p>
<pre class="r"><code>wildebeest_seasons %&gt;% filter(year == 2017) %&gt;% 
  pairwise.wilcox.test(.$size, .$season, data=.)</code></pre>
<pre><code>## 
##  Pairwise comparisons using Wilcoxon rank sum test 
## 
## data:  .$size and .$season 
## 
##             dry    long rains
## long rains  &lt;2e-16 -         
## short rains 0.025  &lt;2e-16    
## 
## P value adjustment method: holm</code></pre>
<p>The results show us that the least significant differnce in 2017 was between the dry and short rains seasons, as confirmed by the boxplots above. We can apply the Kruskal-Wallis test across the entire naboisho dataset. Thsi time we’ll test if year on year mean group sizes changes are significant:</p>
<pre class="r"><code># Apply Kruskal-Wallis to each species to see if change in mean year on year is significant

species_kw_test &lt;- naboisho %&gt;% 
  # Filter species recorded as None
  filter(species != &quot;None&quot;) %&gt;%
  # Count testable data
  count(species, year) %&gt;%
  # Remove any data less with a count less than 10
  filter(n&gt;10) %&gt;%
  # Create testable data set
  left_join(naboisho) %&gt;%
  # Nest each species group
  nest(-species) %&gt;%
  # Map each group to the Kruskal test
  mutate(kruskal_res = map(data, ~ kruskal.test(.x$size, .x$year)),
         kruskal     = map(kruskal_res, broom::tidy)) %&gt;%
  # We dont needed the nested data frames anymore
  dplyr::select(-data) %&gt;%
  # Unnest the result
  unnest(kruskal)

# Select species where we cannot reject the null-hypothesis
species_kw_test %&gt;% 
  filter(.$p.value &gt; 0.05)</code></pre>
<pre><code>## # A tibble: 10 x 6
##    species        kruskal_res statistic p.value parameter method           
##    &lt;fct&gt;          &lt;list&gt;          &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;            
##  1 Black Backed … &lt;htest&gt;         4.89   0.0869         2 Kruskal-Wallis r…
##  2 Buffalo        &lt;htest&gt;         3.88   0.144          2 Kruskal-Wallis r…
##  3 Coke Hartebee… &lt;htest&gt;         0.501  0.778          2 Kruskal-Wallis r…
##  4 Dik Dik        &lt;htest&gt;         4.00   0.136          2 Kruskal-Wallis r…
##  5 Elephant       &lt;htest&gt;         5.63   0.0598         2 Kruskal-Wallis r…
##  6 Lion           &lt;htest&gt;         2.25   0.134          1 Kruskal-Wallis r…
##  7 Ostrich        &lt;htest&gt;         0.857  0.652          2 Kruskal-Wallis r…
##  8 Topi           &lt;htest&gt;         5.39   0.145          3 Kruskal-Wallis r…
##  9 Vervet Monkey  &lt;htest&gt;         1.20   0.548          2 Kruskal-Wallis r…
## 10 Waterbuck      &lt;htest&gt;         0.353  0.552          1 Kruskal-Wallis r…</code></pre>
<p>The table above lists the species where cannot infer anything from year-on-year mean group size changes.</p>
</div>
<div id="implications-1" class="section level2">
<h2>Implications</h2>
<p>Statistical modelling using regression will typically assume homogenous variance. This can be checked by plotting the model residuals against the fitted values. A good fit will have have similar residual variation across all values. In order to address heterogeneity of variance in the response variable, it is possible to transform it; for example via a log transformation. Alternatively, modelling approaches that do not assume equal variance can be used.</p>
</div>
</div>
<div id="normality" class="section level1">
<h1>Normality</h1>
<p>A significant number of statistical modelling tools assuming the data are normally distributed. For example, linear regression assumes the data us normally distributed.</p>
<div id="histogram" class="section level2">
<h2>Histogram</h2>
<p>The following plot shows a histogram for the weight of 1,193 sparrows <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>.</p>
<pre class="r"><code># Load sparrows data set
sparrows &lt;- read.delim(&quot;/Users/anthony/Documents/GitHub/ComputationalEcology/data_analysis_files/Sparrows.txt&quot;)

ggplot(sparrows, aes(x = wt)) + 
  geom_histogram(color = &quot;black&quot;, binwidth = 0.25) +
    theme_minimal() +
    labs(x = &quot;Weight (g)&quot;, 
         y = &quot;Frequency&quot;)</code></pre>
<p><img src="1_data_analysis_files/figure-html/unnamed-chunk-1-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="density-plot" class="section level2">
<h2>Density plot</h2>
<p>Whislt the histograme appears to have an approximate normal shape, we can plot a density plot to have a better visual check?</p>
<pre class="r"><code>library(ggpubr)
ggdensity(data = sparrows$wt,
          main = &quot;Density plot of sparrow weight&quot;,
          xlab = &quot;Sparrow weight&quot;) </code></pre>
<p><img src="1_data_analysis_files/figure-html/density_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="q-q-plot" class="section level2">
<h2>Q-Q Plot</h2>
<p>The normal Q-Q plot is an alternative graphical method of assessing normality to the histogram. The scatter compares the data to a perfect normal distribution. The scatter should lie as close to the line as possible with no obvious pattern coming away from the line for the data to be considered normally distributed. The Q-Q plot for the sparrow weight data is plotted below:</p>
<pre class="r"><code>ggqqplot(sparrows$wt)</code></pre>
<p><img src="1_data_analysis_files/figure-html/qq_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We can see that the Q-Q plot departs from the theoretical line at extremes. If we subset the data by month and plot a sparrow weight histograme for each month, we can see how the data varies considerably throughout the year.</p>
<pre class="r"><code>sparrows %&gt;%
  mutate(Month = lubridate::month(Month, abbr = T, label = T)) %&gt;%
ggplot(aes(x = wt)) + 
  geom_histogram(color = &quot;black&quot;, binwidth = 0.25) +
    theme_minimal() +
    labs(x = &quot;Weight (g)&quot;, 
         y = &quot;Frequency&quot;) +
  facet_wrap(. ~ Month)</code></pre>
<p><img src="1_data_analysis_files/figure-html/spp_weight_month-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This is most likely due to sampling bias; more samples during the summer. If we plot a historgram of the month the observation was recorded we do indeed see a skew towards summer months:</p>
<pre class="r"><code>sparrows %&gt;%
  mutate(Month = lubridate::month(Month, abbr = T, label = T)) %&gt;%
  ggplot(aes(Month, fill=Month)) +
    geom_histogram(stat=&quot;count&quot;) +
    theme_bw()</code></pre>
<pre><code>## Warning: Ignoring unknown parameters: binwidth, bins, pad</code></pre>
<p><img src="1_data_analysis_files/figure-html/sparrow_months-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="implications-2" class="section level2">
<h2>Implications</h2>
<p>If tests suggest that the data are not normally distributed it may be possible to log transform (or take the square root) the response variable and then repeat the normality checks. If we need to undertake further tests that are depednent on normality, for example ANOVA, then we can use non parametric tests such as the <em>Kruskal-Wallis test</em> for a one-way ANOVA test.</p>
</div>
</div>
<div id="zero-inflation" class="section level1">
<h1>Zero inflation</h1>
<p>When studying species populations ecologists will often record species count data, and then seek to study how species abundance varies as a function of covariates such as time, habitat type, temperature, weather etc. If species are not observed during a survey, this is recorded as an absence. This can lead to over-dispersion within the data.</p>
<p>This being the case we should proceed with modelling techniques that are based on <em>zero-inflated</em> probability distribution. Such distributions allow for frequent zero-valued observations and one common one is a zero-inflated Poisson (ZIP) model, as well as the zero-inflated negative binomial (ZINB).</p>
<p>In order to determine the number of zeros within a dataset, we can simply plot a histogram of occurence data. Often within survye data species absense is implicit in that only a species presence is recorded. If this is the case then the first thing we should do is record the absence explicitly. In this way, we have a true record of the <em>sampling effort</em>.</p>
<p>If we look at the species data for Giraffe from the Naboisho data set:</p>
<pre class="r"><code># Number of distinct transects undertaken
naboisho %&gt;% 
  distinct(Date,Sample.Label) %&gt;%
  count()</code></pre>
<pre><code>## # A tibble: 1 x 1
##       n
##   &lt;int&gt;
## 1  1099</code></pre>
<pre class="r"><code># Number of transects where Giraffe were recorded
naboisho %&gt;% 
  filter(species == &quot;Giraffe&quot;) %&gt;% 
  distinct(Date, Sample.Label) %&gt;% 
  count()</code></pre>
<pre><code>## # A tibble: 1 x 1
##       n
##   &lt;int&gt;
## 1   361</code></pre>
<pre class="r"><code># Plot a histograme of observation sizes
naboisho %&gt;% 
  filter(species == &quot;Giraffe&quot;, size &lt; 300) %&gt;%
  ggplot(aes(x = size)) + 
  geom_histogram(color = &quot;black&quot;, binwidth = 1) +
    theme_minimal() +
    labs(x = &quot;Giraffe group size&quot;, 
         y = &quot;Frequency&quot;)</code></pre>
<p><img src="1_data_analysis_files/figure-html/giraffe_data-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>So we can see that there were 1099 transects undertaken, but only 361 of them have records of Giraffe. So we have not explicitly recorded the fact that during 738 transects no Giraffe were observed. The histogram shows that the vast majority of observations were just for one Giraffe. So let’s update the data to incorporate this:</p>
<pre class="r"><code># Number of transects where Giraffe were recorded
giraffe_transects &lt;- naboisho %&gt;% 
  filter(species == &quot;Giraffe&quot;) %&gt;% 
  distinct(Sample.Label, Date)
  
# Select transects where no target species was detected
absence_transects &lt;- naboisho %&gt;% 
  distinct(Sample.Label, Date) %&gt;%
  anti_join(., giraffe_transects, copy = T) %&gt;%
  semi_join(naboisho, ., by=c(&quot;Sample.Label&quot;,&quot;Date&quot;), copy=T) %&gt;% 
  group_by(Sample.Label, Date) %&gt;% 
  slice(1) %&gt;%
  mutate(Species = &quot;NA&quot;,
         distance = NA,
         visit = NA,
         size     = 0) %&gt;%
  as.data.frame()

# Combine missing transects with target species transects
complete_transects &lt;- naboisho %&gt;%
  filter(species == &quot;Giraffe&quot;, size &lt;300) %&gt;% 
  rbind(absence_transects[,1:17])

# Plot a histogram of observation sizes with absence transects included
complete_transects %&gt;% 
  ggplot(aes(x = size)) + 
  geom_histogram(color = &quot;black&quot;, binwidth = 1) +
    theme_minimal() +
    labs(x = &quot;Giraffe group size&quot;, 
         y = &quot;Frequency&quot;)</code></pre>
<p><img src="1_data_analysis_files/figure-html/giraffe_zero_inflated-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Check that the number of transects are what we&#39;d expect - 1099
complete_transects %&gt;% 
  distinct(Date, Sample.Label) %&gt;% 
  count()</code></pre>
<pre><code>## # A tibble: 1 x 1
##       n
##   &lt;int&gt;
## 1  1099</code></pre>
<p>Now we see that by including the transects where Giraffe were not observed (zero-inflating the survey data) the histogram has changed significantly.</p>
<div id="implications-3" class="section level2">
<h2>Implications</h2>
<p><a href="https://fukamilab.github.io/BIO202/04-C-zero-data.html" class="uri">https://fukamilab.github.io/BIO202/04-C-zero-data.html</a></p>
</div>
</div>
<div id="collinearity" class="section level1">
<h1>Collinearity</h1>
<p>Collinearity is when covariates (the independent variables of a data set) are significantly correlated. This is typically a problem as collinearity will inflate the variance of modelled regression coefficients and therefore it is important to detect and remove the redundancy introduced, by dropping one of the covariates where the collinearity is observed. Failure to do this will increase standard errors of regression parameters and therefore inflate p-values [1^] when incorporating such data into regression models.</p>
<p>In order to demonstrate collinearity within independent variables, we can look at the <code>doubs</code> dataset<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. This is a dataset that records fish species from a survey of the river Doubs in France, together with the spatial coordinates for the 30 survey sites and environmental covariates for each of the site. We can examine collinearity between the environmental covarites from <code>doubs</code>, by using a correlation matrix. This shows scatterplots between covarite data, together with Pearson coefficients.</p>
<pre class="r"><code>library(PerformanceAnalytics) 
library(ade4)

#Let&#39;s load the data
data(doubs)
# Data representing water chemistry assay for each site...
env &lt;- doubs$env

chart.Correlation(env, 
                  histogram=TRUE, 
                  method = &quot;pearson&quot;,
                  pch=19,
                  title = &quot;Correlation Matrix&quot;)</code></pre>
<p><img src="1_data_analysis_files/figure-html/env_correlation-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>We can easily see that there are a number of covariates with significant (&gt; c.90%) collinearity between. The ecological reasons for this correlation are outlined below.</p>
<p>Topological environmental covariates:</p>
<ul>
<li><code>dfs</code> (distance from source) and <code>alt</code> (altitude) - As we move away from the source at theop of a mountain, the altitude decreases.</li>
<li><code>dfs</code> (distance from source) and <code>flo</code> (mean flow rate) - again, as we move away from the source, the flow rate of water increases.</li>
<li><code>alt</code> (altitude) and <code>flo</code> (mean flow rate) - as the altitude decreases, again the flow rate increases.</li>
</ul>
<p>Water-chemistry environmental covariates:</p>
<ul>
<li><code>pho</code> (phosphate concentrate) and <code>amm</code> (ammonium concentrate) - ammonium is an indicator of organic pollution and phosphorus is a common constituent of agricultural fertilizers, manure, and organic wastes <a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>. So it would appear that likely that their join presence is due to agricultural activities.</li>
<li><p><code>amm</code> (ammonium concentrate) and <code>bdo</code> (biological oxygen demand) - ammonium and biological oxygen demand are key indicators of organic pollution in water. BOD shows how much dissolved oxygen is needed for the decomposition of organic matter present in water.</p></li>
<li><p><code>pho</code> (phosphate concentrate) and <code>bdo</code> (biological oxygen demand) - high levels of phosphorous in water bodies lead to eutriphication, which is likely to be a direct result of phosphate inputs and ammonium organic waste from farming <a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>.</p></li>
</ul>
<p>For each of the covariates pairs outlined above, there is clearly a linear relationship between them. In order to avoid the side-effects mentioned above, we need to select the smallest subset of covariates that explains as much of the overall variation in the response variable(s). We will be exploring indpendent variable selection when fitting models for species distribution modelling.</p>
</div>
<div id="associations" class="section level1">
<h1>Associations</h1>
<p>Visualising the relationship between the response variable(s) and covariates can help to provide an initial understanding that may aid model selection technique, as well as highlighting observations that do not comply with the general pattern between response and covariate variables.</p>
<p>We can do this for the <code>doubs</code> data set. The plot below shows for each covariate (x axis), how the abundance for different species responds (y axis).</p>
<pre class="r"><code>library(reshape2)

# Melt dataframe to give species data
species &lt;- doubs$fish
species$site &lt;- 1:30
df_melt_species &lt;- melt(species, 
                        measure.vars = 1:28, 
                        id.vars = &quot;site&quot;, 
                        value.name = &quot;abundance&quot;, 
                        variable.name = &quot;species&quot;)
  
environ &lt;- doubs$env
environ$site &lt;- 1:30

# Melt dataframe to give environmental data
df_melt_environ &lt;- melt(environ, 
                        measure.vars = 1:11, 
                        id.vars = &quot;site&quot;, 
                        value.name = &quot;cov_value&quot;, 
                        variable.name = &quot;env_cov&quot;)

# Now plot joined data to see response (species abundance) v covariates
# Begin by joining both melted datasets
full_join(df_melt_species,df_melt_environ,&quot;site&quot;, keep = F) %&gt;%
  # Remove site as a species column
  filter(species != &quot;site&quot;) %&gt;%
  
  ggplot() +
  # Plot abundance for against each covariate
  geom_point(aes( x = cov_value, y = abundance), size = 0.5) +
  # Fit a GAM for each plot and plot a smooth
  stat_smooth(aes( x = cov_value, 
                   y = abundance), 
              method = &quot;gam&quot;, 
              # Use cubic splines as basis for GAM
              formula = y ~ s(x, bs = &quot;cs&quot;), 
              size = 0.5) +
  # Plot covariate by species - big grid!
  facet_grid(species ~ env_cov , scales=&quot;free&quot;) +
  theme_minimal() +
  # Flip x axis labels - otherwise they dont fit
  theme(axis.text.x = element_text(angle = 90, hjust = 1))</code></pre>
<p><img src="1_data_analysis_files/figure-html/3dscatterplot-1.png" width="960" /></p>
<p>We can see that although there is a lot of information here, we can see some clear types of behaviour for abundnace ~ covariate. For example, species abundance typically reduces as altitude increases, for all species types. If we look at <code>dfs</code> (distance from source), we can see that there are some species that have peak abundnace midstream (Cogo and Satr), where as most othere species have maximum abundance downstream, at the mouth of the river. We can see that species abundance is realtively high at low levels of ammonimum for all species, but abunance is zero for anything above 50 mgL<span class="math inline">\(^-1\)</span></p>
<p>Why isn’t pH plotting?!</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Zuur AF, Leno EN, Elphick CS (2010) A protocol for data exploration to avoid common statistical problems. <em>Methods in Ecology and Evolution</em><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Zuur AF, Leno EN, Elphick CS (2010) A protocol for data exploration to avoid common statistical problems. <em>Methods in Ecology and Evolution</em><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Verneaux, J. (1973) Cours d’eau de Franche-Comté (Massif du Jura). Recherches écologiques sur le réseau hydrographique du Doubs. Essai de biotypologie. Thèse d’état, Besançon. 1–257. <em>Doubs river fish communities</em>. <a href="https://www.davidzeleny.net/anadat-r/doku.php/en:data:doubs" class="uri">https://www.davidzeleny.net/anadat-r/doku.php/en:data:doubs</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="https://www.eea.europa.eu/data-and-maps/indicators/freshwater-quality/freshwater-quality-assessment-published-may-2" class="uri">https://www.eea.europa.eu/data-and-maps/indicators/freshwater-quality/freshwater-quality-assessment-published-may-2</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p><a href="https://www.eea.europa.eu/data-and-maps/indicators/freshwater-quality/freshwater-quality-assessment-published-may-2" class="uri">https://www.eea.europa.eu/data-and-maps/indicators/freshwater-quality/freshwater-quality-assessment-published-may-2</a><a href="#fnref5">↩</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
